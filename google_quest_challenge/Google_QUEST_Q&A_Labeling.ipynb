{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Google QUEST Q&A Labeling.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWtsTwXCOw7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erbMa4__79Bf",
        "colab_type": "text"
      },
      "source": [
        "#### Imports and TPU setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8LxAXfCwdYL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "075d7603-8752-4730-84d9-251b56ca86b9"
      },
      "source": [
        "! pip install --upgrade kaggle -q\n",
        "! pip install transformers -q\n",
        "! pip install emoji -qq\n",
        "! pip install googletrans -qq"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |█████▌                          | 10kB 22.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 30kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 51kB 2.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 2.0MB/s \n",
            "\u001b[?25h  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for slugify (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 890kB 3.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 10.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 20.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.0MB 27.6MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 51kB 1.7MB/s \n",
            "\u001b[?25h  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 61kB 3.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 962kB 5.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 5.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 6.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 5.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 6.3MB/s \n",
            "\u001b[?25h  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for contextvars (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQDCshNp2v52",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import transformers\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from google.colab import files\n",
        "import tensorflow_datasets as tfds\n",
        "from transformers import BertTokenizer\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from transformers import TFAutoModel, AutoTokenizer\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout, GlobalAveragePooling1D, Concatenate\n",
        "\n",
        "\n",
        "from setup import set_TPU\n",
        "from text_models import XLMRobertaInputs, BertInputs\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSm866_x7d1s",
        "colab_type": "text"
      },
      "source": [
        "#### Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLGJ4FpRwn8e",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "3fb334a1-320e-491d-ee61-884b174401de"
      },
      "source": [
        "files.upload()\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle competitions download -c google-quest-challenge"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1458c940-a06c-4cbc-a7ba-cb87bb65dbb1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1458c940-a06c-4cbc-a7ba-cb87bb65dbb1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Downloading google-quest-challenge.zip to /content\n",
            "100% 4.85M/4.85M [00:00<00:00, 34.6MB/s]\n",
            "100% 4.85M/4.85M [00:00<00:00, 34.5MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMpit1gy1hBo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f3ff0bf0-48f8-4fb9-cf96-2e8f6fae8cd0"
      },
      "source": [
        "!unzip '/content/google-quest-challenge.zip'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/google-quest-challenge.zip\n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qvnS8kP1OpO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('/content/train.csv')\n",
        "test = pd.read_csv('/content/test.csv')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUZlK_Nc44xY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "outputId": "1797abc8-00f9-49b6-fe63-0caf0d787f17"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qa_id</th>\n",
              "      <th>question_title</th>\n",
              "      <th>question_body</th>\n",
              "      <th>question_user_name</th>\n",
              "      <th>question_user_page</th>\n",
              "      <th>answer</th>\n",
              "      <th>answer_user_name</th>\n",
              "      <th>answer_user_page</th>\n",
              "      <th>url</th>\n",
              "      <th>category</th>\n",
              "      <th>host</th>\n",
              "      <th>question_asker_intent_understanding</th>\n",
              "      <th>question_body_critical</th>\n",
              "      <th>question_conversational</th>\n",
              "      <th>question_expect_short_answer</th>\n",
              "      <th>question_fact_seeking</th>\n",
              "      <th>question_has_commonly_accepted_answer</th>\n",
              "      <th>question_interestingness_others</th>\n",
              "      <th>question_interestingness_self</th>\n",
              "      <th>question_multi_intent</th>\n",
              "      <th>question_not_really_a_question</th>\n",
              "      <th>question_opinion_seeking</th>\n",
              "      <th>question_type_choice</th>\n",
              "      <th>question_type_compare</th>\n",
              "      <th>question_type_consequence</th>\n",
              "      <th>question_type_definition</th>\n",
              "      <th>question_type_entity</th>\n",
              "      <th>question_type_instructions</th>\n",
              "      <th>question_type_procedure</th>\n",
              "      <th>question_type_reason_explanation</th>\n",
              "      <th>question_type_spelling</th>\n",
              "      <th>question_well_written</th>\n",
              "      <th>answer_helpful</th>\n",
              "      <th>answer_level_of_information</th>\n",
              "      <th>answer_plausible</th>\n",
              "      <th>answer_relevance</th>\n",
              "      <th>answer_satisfaction</th>\n",
              "      <th>answer_type_instructions</th>\n",
              "      <th>answer_type_procedure</th>\n",
              "      <th>answer_type_reason_explanation</th>\n",
              "      <th>answer_well_written</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>What am I losing when using extension tubes in...</td>\n",
              "      <td>After playing around with macro photography on...</td>\n",
              "      <td>ysap</td>\n",
              "      <td>https://photo.stackexchange.com/users/1024</td>\n",
              "      <td>I just got extension tubes, so here's the skin...</td>\n",
              "      <td>rfusca</td>\n",
              "      <td>https://photo.stackexchange.com/users/1917</td>\n",
              "      <td>http://photo.stackexchange.com/questions/9169/...</td>\n",
              "      <td>LIFE_ARTS</td>\n",
              "      <td>photo.stackexchange.com</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>What is the distinction between a city and a s...</td>\n",
              "      <td>I am trying to understand what kinds of places...</td>\n",
              "      <td>russellpierce</td>\n",
              "      <td>https://rpg.stackexchange.com/users/8774</td>\n",
              "      <td>It might be helpful to look into the definitio...</td>\n",
              "      <td>Erik Schmidt</td>\n",
              "      <td>https://rpg.stackexchange.com/users/1871</td>\n",
              "      <td>http://rpg.stackexchange.com/questions/47820/w...</td>\n",
              "      <td>CULTURE</td>\n",
              "      <td>rpg.stackexchange.com</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.888889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Maximum protusion length for through-hole comp...</td>\n",
              "      <td>I'm working on a PCB that has through-hole com...</td>\n",
              "      <td>Joe Baker</td>\n",
              "      <td>https://electronics.stackexchange.com/users/10157</td>\n",
              "      <td>Do you even need grooves?  We make several pro...</td>\n",
              "      <td>Dwayne Reid</td>\n",
              "      <td>https://electronics.stackexchange.com/users/64754</td>\n",
              "      <td>http://electronics.stackexchange.com/questions...</td>\n",
              "      <td>SCIENCE</td>\n",
              "      <td>electronics.stackexchange.com</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.888889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Can an affidavit be used in Beit Din?</td>\n",
              "      <td>An affidavit, from what i understand, is basic...</td>\n",
              "      <td>Scimonster</td>\n",
              "      <td>https://judaism.stackexchange.com/users/5151</td>\n",
              "      <td>Sending an \"affidavit\" it is a dispute between...</td>\n",
              "      <td>Y     e     z</td>\n",
              "      <td>https://judaism.stackexchange.com/users/4794</td>\n",
              "      <td>http://judaism.stackexchange.com/questions/551...</td>\n",
              "      <td>CULTURE</td>\n",
              "      <td>judaism.stackexchange.com</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>How do you make a binary image in Photoshop?</td>\n",
              "      <td>I am trying to make a binary image. I want mor...</td>\n",
              "      <td>leigero</td>\n",
              "      <td>https://graphicdesign.stackexchange.com/users/...</td>\n",
              "      <td>Check out Image Trace in Adobe Illustrator. \\n...</td>\n",
              "      <td>q2ra</td>\n",
              "      <td>https://graphicdesign.stackexchange.com/users/...</td>\n",
              "      <td>http://graphicdesign.stackexchange.com/questio...</td>\n",
              "      <td>LIFE_ARTS</td>\n",
              "      <td>graphicdesign.stackexchange.com</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   qa_id  ... answer_well_written\n",
              "0      0  ...            1.000000\n",
              "1      1  ...            0.888889\n",
              "2      2  ...            0.888889\n",
              "3      3  ...            1.000000\n",
              "4      5  ...            1.000000\n",
              "\n",
              "[5 rows x 41 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-fFvtUW47SA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "91cf501e-978e-49d0-a6a9-8fdcf29365a5"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qa_id</th>\n",
              "      <th>question_title</th>\n",
              "      <th>question_body</th>\n",
              "      <th>question_user_name</th>\n",
              "      <th>question_user_page</th>\n",
              "      <th>answer</th>\n",
              "      <th>answer_user_name</th>\n",
              "      <th>answer_user_page</th>\n",
              "      <th>url</th>\n",
              "      <th>category</th>\n",
              "      <th>host</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>Will leaving corpses lying around upset my pri...</td>\n",
              "      <td>I see questions/information online about how t...</td>\n",
              "      <td>Dylan</td>\n",
              "      <td>https://gaming.stackexchange.com/users/64471</td>\n",
              "      <td>There is no consequence for leaving corpses an...</td>\n",
              "      <td>Nelson868</td>\n",
              "      <td>https://gaming.stackexchange.com/users/97324</td>\n",
              "      <td>http://gaming.stackexchange.com/questions/1979...</td>\n",
              "      <td>CULTURE</td>\n",
              "      <td>gaming.stackexchange.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>46</td>\n",
              "      <td>Url link to feature image in the portfolio</td>\n",
              "      <td>I am new to Wordpress. i have issue with Featu...</td>\n",
              "      <td>Anu</td>\n",
              "      <td>https://wordpress.stackexchange.com/users/72927</td>\n",
              "      <td>I think it is possible with custom fields.\\n\\n...</td>\n",
              "      <td>Irina</td>\n",
              "      <td>https://wordpress.stackexchange.com/users/27233</td>\n",
              "      <td>http://wordpress.stackexchange.com/questions/1...</td>\n",
              "      <td>TECHNOLOGY</td>\n",
              "      <td>wordpress.stackexchange.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>70</td>\n",
              "      <td>Is accuracy, recoil or bullet spread affected ...</td>\n",
              "      <td>To experiment I started a bot game, toggled in...</td>\n",
              "      <td>Konsta</td>\n",
              "      <td>https://gaming.stackexchange.com/users/37545</td>\n",
              "      <td>You do not have armour in the screenshots. Thi...</td>\n",
              "      <td>Damon Smithies</td>\n",
              "      <td>https://gaming.stackexchange.com/users/70641</td>\n",
              "      <td>http://gaming.stackexchange.com/questions/2154...</td>\n",
              "      <td>CULTURE</td>\n",
              "      <td>gaming.stackexchange.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>132</td>\n",
              "      <td>Suddenly got an I/O error from my external HDD</td>\n",
              "      <td>I have used my Raspberry Pi as a torrent-serve...</td>\n",
              "      <td>robbannn</td>\n",
              "      <td>https://raspberrypi.stackexchange.com/users/17341</td>\n",
              "      <td>Your Western Digital hard drive is disappearin...</td>\n",
              "      <td>HeatfanJohn</td>\n",
              "      <td>https://raspberrypi.stackexchange.com/users/1311</td>\n",
              "      <td>http://raspberrypi.stackexchange.com/questions...</td>\n",
              "      <td>TECHNOLOGY</td>\n",
              "      <td>raspberrypi.stackexchange.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>200</td>\n",
              "      <td>Passenger Name - Flight Booking Passenger only...</td>\n",
              "      <td>I have bought Delhi-London return flights for ...</td>\n",
              "      <td>Amit</td>\n",
              "      <td>https://travel.stackexchange.com/users/29089</td>\n",
              "      <td>I called two persons who work for Saudia (tick...</td>\n",
              "      <td>Nean Der Thal</td>\n",
              "      <td>https://travel.stackexchange.com/users/10051</td>\n",
              "      <td>http://travel.stackexchange.com/questions/4704...</td>\n",
              "      <td>CULTURE</td>\n",
              "      <td>travel.stackexchange.com</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   qa_id  ...                           host\n",
              "0     39  ...       gaming.stackexchange.com\n",
              "1     46  ...    wordpress.stackexchange.com\n",
              "2     70  ...       gaming.stackexchange.com\n",
              "3    132  ...  raspberrypi.stackexchange.com\n",
              "4    200  ...       travel.stackexchange.com\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "130psWX0F5kS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b3bd48da-ade5-49c3-bcba-399d7554e819"
      },
      "source": [
        "print(f\"train shape: {train.shape} \\nvalidation shape: {test.shape}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train shape: (6079, 41) \n",
            "validation shape: (476, 11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joA3n5aK8CZL",
        "colab_type": "text"
      },
      "source": [
        "#### Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfikgRoUiyPO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_categories = list(train.columns[11:])\n",
        "input_categories = list(train.columns[[1,2,5]])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6L59boAqTZcJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['question_title_body']  = train['question_title'] + '. ' + train['question_body']"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uB3CzUAlCRnq",
        "colab_type": "text"
      },
      "source": [
        "#### Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbwrTab8bqMH",
        "colab_type": "text"
      },
      "source": [
        "##### Model by CLS token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otT7hI3B8E9G",
        "colab_type": "text"
      },
      "source": [
        "###### Build model inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XswqXatJZjmY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7219f5c9-8327-4eb2-9ff2-51132b61e35b"
      },
      "source": [
        "strategy = set_TPU()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running on TPU: grpc://10.112.218.106:8470\n",
            "REPLICAS: 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFM174YB3e3d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Configuration\n",
        "MODEL = 'jplu/tf-xlm-roberta-large'\n",
        "EPOCHS = 3\n",
        "MAX_LEN = 96\n",
        "\n",
        "BATCH_SIZE = 16 * strategy.num_replicas_in_sync"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lbuoa9-snYJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "bc370913-65c3-43c5-df06-b7c4fef55c8e"
      },
      "source": [
        "xlmroberta_inputs_train = XLMRobertaInputs(train[['question_title_body','answer']].iloc[:5000].values.tolist(), train[output_categories].iloc[:5000].values, max_length=MAX_LEN, batch_size=BATCH_SIZE)\n",
        "%time train_inputs = xlmroberta_inputs_train.process_examples(train=True)\n",
        "\n",
        "xlmroberta_inputs_val = XLMRobertaInputs(train[['question_title_body','answer']].iloc[5000:].values.tolist(), train[output_categories].iloc[5000:].values, max_length=MAX_LEN, batch_size=BATCH_SIZE)\n",
        "%time validation_inputs = xlmroberta_inputs_val.process_examples(train=False)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 8.64 s, sys: 159 ms, total: 8.8 s\n",
            "Wall time: 8.82 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2.09 s, sys: 8.73 ms, total: 2.1 s\n",
            "Wall time: 2.11 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NpfLJDbsRDPT"
      },
      "source": [
        "###### Build model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gi84ja9VlKn3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(transformer,max_len):\n",
        "    \n",
        "    input_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
        "    sequence_output = transformer(input_ids)[0]\n",
        "    cls_token = sequence_output[:, 0, :]\n",
        "    cls_token = Dropout(0.2)(cls_token)\n",
        "    cls_token = Dense(512,activation='relu')(cls_token)\n",
        "    out = Dense(len(output_categories), activation='sigmoid')(cls_token)\n",
        "\n",
        "    model = Model(inputs=input_ids, outputs=out)\n",
        "    model.compile(Adam(lr=2e-5),  loss='binary_crossentropy')\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDNblmDYurnr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "8c624441-dec0-44bf-f0f4-383843f09d60"
      },
      "source": [
        "transformer_layer = TFAutoModel.from_pretrained(MODEL)\n",
        "model = build_model(transformer_layer, max_len=MAX_LEN)\n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at jplu/tf-xlm-roberta-large were not used when initializing TFXLMRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFXLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing TFXLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFXLMRobertaModel were initialized from the model checkpoint at jplu/tf-xlm-roberta-large.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_ids (InputLayer)       [(None, 96)]              0         \n",
            "_________________________________________________________________\n",
            "tfxlm_roberta_model (TFXLMRo ((None, 96, 1024), (None, 559890432 \n",
            "_________________________________________________________________\n",
            "tf_op_layer_strided_slice (T [(None, 1024)]            0         \n",
            "_________________________________________________________________\n",
            "dropout_74 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 30)                15390     \n",
            "=================================================================\n",
            "Total params: 560,430,622\n",
            "Trainable params: 560,430,622\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kF2vMATmffgM",
        "colab_type": "text"
      },
      "source": [
        "###### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_hCDb4Ycq2g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "f95505f0-c264-4730-fc40-975a606ab9d0"
      },
      "source": [
        "n_steps = train.shape[0]//BATCH_SIZE\n",
        "\n",
        "train_history = model.fit(train_inputs, validation_data=validation_inputs, steps_per_epoch=n_steps, epochs=EPOCHS, verbose=1)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "47/47 [==============================] - 1061s 23s/step - loss: 0.4586 - val_loss: 0.4083\n",
            "Epoch 2/3\n",
            "47/47 [==============================] - 1055s 22s/step - loss: 0.4052 - val_loss: 0.3878\n",
            "Epoch 3/3\n",
            "47/47 [==============================] - 1054s 22s/step - loss: 0.3877 - val_loss: 0.3804\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74-xxZKpLb39",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "9c74336e-a6e7-4c2f-878d-b4b1ae1e49b6"
      },
      "source": [
        "text = [['its a nice day', 'the weather outside seems to be good']]\n",
        "token = xlmroberta_inputs_train.tokenizer.batch_encode_plus(text,\n",
        "                        max_length = MAX_LEN, # max length of the text that can go to BERT\n",
        "                        pad_to_max_length = True, # add [PAD] tokens\n",
        "                        truncation = True\n",
        "                    )\n",
        "xlmroberta_inputs_pred = np.array(token['input_ids'])\n",
        "\n",
        "model.predict(xlmroberta_inputs_pred)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.79775965, 0.5225271 , 0.12118098, 0.63759834, 0.5774739 ,\n",
              "        0.6357765 , 0.58222264, 0.63370115, 0.28555083, 0.02138367,\n",
              "        0.54605   , 0.24992555, 0.13134766, 0.04937392, 0.08555287,\n",
              "        0.1759719 , 0.22008052, 0.25450706, 0.39080173, 0.03756759,\n",
              "        0.77141625, 0.8313895 , 0.5324839 , 0.8038827 , 0.9214682 ,\n",
              "        0.8090356 , 0.25202483, 0.11678043, 0.40678966, 0.70252013]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwT5-M7kT-U8",
        "colab_type": "text"
      },
      "source": [
        "##### BERT model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nXSDopt56hBv"
      },
      "source": [
        "###### Build model inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfCwK4yyT-0s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "cf51b46b-0b0e-491f-d899-691fe08c6ad9"
      },
      "source": [
        "Bert_inputs_train = BertInputs(train[['question_title_body','answer']].iloc[:5000].values.tolist(), train[output_categories].iloc[:5000].values, max_length=MAX_LEN, batch_size=BATCH_SIZE)\n",
        "%time train_inputs = Bert_inputs_train.process_examples(train=True)\n",
        "\n",
        "Bert_inputs_val = BertInputs(train[['question_title_body','answer']].iloc[5000:].values.tolist(), train[output_categories].iloc[5000:].values, max_length=MAX_LEN, batch_size=BATCH_SIZE)\n",
        "%time validation_inputs = Bert_inputs_val.process_examples(train=False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 24.9 s, sys: 98.5 ms, total: 25 s\n",
            "Wall time: 25.1 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 5.64 s, sys: 35.3 ms, total: 5.68 s\n",
            "Wall time: 5.69 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2q55i7vsRJBq"
      },
      "source": [
        "###### Build model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CIwvQyTVFYq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(transformer,max_len):\n",
        "    \n",
        "    input_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
        "    \n",
        "    input_masks = Input((max_len,), dtype=tf.int32, name=\"input_masks\")\n",
        "    \n",
        "    input_attention = Input((max_len,), dtype=tf.int32, name=\"input_attention\")\n",
        "    \n",
        "    sequence_output = transformer(input_ids, attention_mask=input_masks, token_type_ids=input_attention)[0]\n",
        "\n",
        "    cls_token = sequence_output[:, 0, :]\n",
        "    cls_token = Dropout(0.2)(cls_token)\n",
        "    cls_token = Dense(512,activation='relu')(cls_token)\n",
        "    out = Dense(len(output_categories), activation='sigmoid')(cls_token)\n",
        "\n",
        "    model = Model(inputs=[input_ids, input_masks, input_attention], outputs=out)\n",
        "    model.compile(Adam(lr=2e-5),  loss='binary_crossentropy')\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsPp5f_mUXBe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "e981bee8-c165-48a3-b0eb-2ba1c2917b36"
      },
      "source": [
        "transformer_layer = TFAutoModel.from_pretrained(\"bert-base-uncased\")\n",
        "model = build_model(transformer_layer, max_len=MAX_LEN)\n",
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 96)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_masks (InputLayer)        [(None, 96)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_attention (InputLayer)    [(None, 96)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model (TFBertModel)     ((None, 96, 768), (N 109482240   input_ids[0][0]                  \n",
            "                                                                 input_masks[0][0]                \n",
            "                                                                 input_attention[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_1 (Te [(None, 768)]        0           tf_bert_model[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_112 (Dropout)           (None, 768)          0           tf_op_layer_strided_slice_1[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 512)          393728      dropout_112[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 30)           15390       dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 109,891,358\n",
            "Trainable params: 109,891,358\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SqeLZp1H6WRc"
      },
      "source": [
        "###### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9awkl0FIlQI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "2f87474d-3dca-42a4-8870-717f18340949"
      },
      "source": [
        "n_steps = train.shape[0]//BATCH_SIZE\n",
        "\n",
        "train_history = model.fit(train_inputs, validation_data=validation_inputs, steps_per_epoch=n_steps, epochs=EPOCHS, verbose=1)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "47/47 [==============================] - 357s 8s/step - loss: 0.4821 - val_loss: 0.4263\n",
            "Epoch 2/3\n",
            "47/47 [==============================] - 351s 7s/step - loss: 0.4343 - val_loss: 0.4256\n",
            "Epoch 3/3\n",
            "47/47 [==============================] - 350s 7s/step - loss: 0.4324 - val_loss: 0.4254\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhiKVcLt6mjj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "2b44beb5-7bee-4c2c-ee1a-738745e28960"
      },
      "source": [
        "text = ['its a nice day', 'the weather outside seems to be good']\n",
        "\n",
        "def convert_example_to_feature(text):\n",
        "\n",
        "    return Bert_inputs_train.tokenizer.batch_encode_plus(text,\n",
        "                    add_special_tokens = True, # add [CLS], [SEP]\n",
        "                    max_length = MAX_LEN, # max length of the text that can go to BERT\n",
        "                    pad_to_max_length = True, # add [PAD] tokens\n",
        "                    return_attention_mask = True, # add attention mask to not focus on pad tokens\n",
        "                    return_token_type_ids = True,\n",
        "                    truncation=True\n",
        "                )\n",
        "    \n",
        "def map_example_to_dict(input_ids, attention_masks, token_type_ids):\n",
        "\n",
        "    return {\n",
        "        \"input_ids\": input_ids,\n",
        "        \"token_type_ids\": token_type_ids,\n",
        "        \"attention_mask\": attention_masks,\n",
        "    }\n",
        "\n",
        "def encode_examples(text):\n",
        "\n",
        "    input_ids_list = []\n",
        "    token_type_ids_list = []\n",
        "    attention_mask_list = []\n",
        "        \n",
        "    bert_input = convert_example_to_feature(text)\n",
        "\n",
        "    input_ids_list.append(bert_input['input_ids'])\n",
        "    token_type_ids_list.append(bert_input['token_type_ids'])\n",
        "    attention_mask_list.append(bert_input['attention_mask'])\n",
        "\n",
        "    return tf.data.Dataset.from_tensor_slices((input_ids_list, attention_mask_list, token_type_ids_list)).map(map_example_to_dict)\n",
        "\n",
        "\n",
        "%time pred_inputs = encode_examples(text)\n",
        "\n",
        "model.predict(pred_inputs)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 39.5 ms, sys: 4.11 ms, total: 43.6 ms\n",
            "Wall time: 46 ms\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9026169 , 0.5946907 , 0.04686373, 0.70602137, 0.81683004,\n",
              "        0.81802714, 0.571542  , 0.49712488, 0.21049258, 0.00722891,\n",
              "        0.39576966, 0.2787671 , 0.03532407, 0.01146644, 0.02369136,\n",
              "        0.05350515, 0.4742013 , 0.13612297, 0.33123317, 0.006648  ,\n",
              "        0.80012405, 0.9467379 , 0.65032214, 0.96606654, 0.9729286 ,\n",
              "        0.8701431 , 0.4988237 , 0.11869973, 0.48908088, 0.9162179 ],\n",
              "       [0.9027573 , 0.5924587 , 0.04710203, 0.7063874 , 0.8147415 ,\n",
              "        0.81925344, 0.5713013 , 0.49628526, 0.21291155, 0.00738299,\n",
              "        0.39430138, 0.27792934, 0.03568569, 0.01170361, 0.02402282,\n",
              "        0.05393511, 0.47370946, 0.13593972, 0.33096486, 0.00679541,\n",
              "        0.7994795 , 0.9466686 , 0.64903724, 0.9656198 , 0.97275305,\n",
              "        0.8701525 , 0.49765217, 0.11880806, 0.48939478, 0.9157262 ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_eC9vPXb3lJ",
        "colab_type": "text"
      },
      "source": [
        "##### Model by BERT siamese network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ApG9lKa8IJF",
        "colab_type": "text"
      },
      "source": [
        "###### Build model inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JIzC_bpn3O_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "42f9d202-fbc0-41de-b6f7-300018bbd106"
      },
      "source": [
        "import random\n",
        "from transformers import TFBertModel\n",
        "\n",
        "def convert_to_transformer_inputs(str1, str2, tokenizer, max_sequence_length):\n",
        "    \n",
        "    def return_id(str1, str2, truncation_strategy, length):\n",
        "\n",
        "        inputs = tokenizer.encode_plus(str1, str2,\n",
        "            add_special_tokens=True,\n",
        "            max_length=length,\n",
        "            truncation_strategy=truncation_strategy,\n",
        "            truncation=True)\n",
        "        \n",
        "        input_ids =  inputs[\"input_ids\"]\n",
        "        input_masks = [1] * len(input_ids)\n",
        "        input_segments = inputs[\"token_type_ids\"]\n",
        "        \n",
        "        padding_length = length - len(input_ids)\n",
        "        padding_id = tokenizer.pad_token_id\n",
        "        \n",
        "        input_ids = input_ids + ([padding_id] * padding_length)\n",
        "        input_masks = input_masks + ([0] * padding_length)\n",
        "        input_segments = input_segments + ([0] * padding_length)\n",
        "        \n",
        "        return [input_ids, input_masks, input_segments]\n",
        "        \n",
        "    input_ids_1, input_masks_1, input_segments_1 = return_id(\n",
        "        str1, None, 'longest_first', max_sequence_length)\n",
        "\n",
        "    input_ids_2, input_masks_2, input_segments_2 = return_id(\n",
        "        str2, None, 'longest_first', max_sequence_length)\n",
        "\n",
        "    return [input_ids_1, input_masks_1, input_segments_1,\n",
        "            input_ids_2, input_masks_2, input_segments_2]     \n",
        "\n",
        "def compute_input_arrays(df, columns, tokenizer, max_sequence_length):\n",
        "    \n",
        "    input_ids_1, input_masks_1, input_segments_1 = [], [], []\n",
        "    input_ids_2, input_masks_2, input_segments_2 = [], [], []\n",
        "    for _, instance in tqdm(df[columns].iterrows(), total=len(df)):\n",
        "        str1, str2 = instance[columns[0]], instance[columns[1]]\n",
        "\n",
        "        ids_1, masks_1, segments_1, ids_2, masks_2, segments_2 = \\\n",
        "        convert_to_transformer_inputs(str1, str2, tokenizer, max_sequence_length)\n",
        "        \n",
        "        input_ids_1.append(ids_1)\n",
        "        input_masks_1.append(masks_1)\n",
        "        input_segments_1.append(segments_1)\n",
        "\n",
        "        input_ids_2.append(ids_2)\n",
        "        input_masks_2.append(masks_2)\n",
        "        input_segments_2.append(segments_2)\n",
        "        \n",
        "        \n",
        "    return [np.asarray(input_ids_1, dtype=np.int32), \n",
        "            np.asarray(input_masks_1, dtype=np.int32), \n",
        "            np.asarray(input_segments_1, dtype=np.int32),\n",
        "            np.asarray(input_ids_2, dtype=np.int32), \n",
        "            np.asarray(input_masks_2, dtype=np.int32), \n",
        "            np.asarray(input_segments_2, dtype=np.int32)]\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "input_train = compute_input_arrays(train[['question_title_body','answer']], ['question_title_body','answer'], tokenizer, MAX_LEN)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6079/6079 [00:42<00:00, 144.65it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Z7zrSLKARQUW"
      },
      "source": [
        "###### Build model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8U75zTiJB-x4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def siamese_bert():\n",
        "    \n",
        "    opt = Adam(learning_rate=2e-5)\n",
        "    \n",
        "    id1 = Input((MAX_LEN,), dtype=tf.int32)\n",
        "    id2 = Input((MAX_LEN,), dtype=tf.int32)\n",
        "    \n",
        "    mask1 = Input((MAX_LEN,), dtype=tf.int32)\n",
        "    mask2 = Input((MAX_LEN,), dtype=tf.int32)\n",
        "    \n",
        "    atn1 = Input((MAX_LEN,), dtype=tf.int32)\n",
        "    atn2 = Input((MAX_LEN,), dtype=tf.int32)\n",
        "    \n",
        "    bert_model = TFBertModel.from_pretrained(\"bert-base-uncased\")\n",
        "    bert_model.config.output_hidden_states = False\n",
        "    \n",
        "    embedding1 = bert_model(id1, attention_mask=mask1, token_type_ids=atn1)[0]\n",
        "    embedding2 = bert_model(id2, attention_mask=mask2, token_type_ids=atn2)[0]\n",
        "    \n",
        "    x1 = GlobalAveragePooling1D()(embedding1)\n",
        "    x2 = GlobalAveragePooling1D()(embedding2)\n",
        "    \n",
        "    x = Concatenate()([x1, x2])\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    out = Dense(len(output_categories), activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=[id1, mask1, atn1, id2, mask2, atn2], outputs=out)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP-WrBvXpbWG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "outputId": "204406c0-2590-4683-b4ed-a68a993adb85"
      },
      "source": [
        "model = siamese_bert()\n",
        "model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_7\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_19 (InputLayer)           [(None, 96)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_21 (InputLayer)           [(None, 96)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_23 (InputLayer)           [(None, 96)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_20 (InputLayer)           [(None, 96)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_22 (InputLayer)           [(None, 96)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_24 (InputLayer)           [(None, 96)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model_3 (TFBertModel)   ((None, 96, 768), (N 109482240   input_19[0][0]                   \n",
            "                                                                 input_21[0][0]                   \n",
            "                                                                 input_23[0][0]                   \n",
            "                                                                 input_20[0][0]                   \n",
            "                                                                 input_22[0][0]                   \n",
            "                                                                 input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_6 (Glo (None, 768)          0           tf_bert_model_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_7 (Glo (None, 768)          0           tf_bert_model_3[1][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 1536)         0           global_average_pooling1d_6[0][0] \n",
            "                                                                 global_average_pooling1d_7[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dropout_151 (Dropout)           (None, 1536)         0           concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 512)          786944      dropout_151[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 30)           15390       dense_6[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 110,284,574\n",
            "Trainable params: 110,284,574\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAito4XtcAc0",
        "colab_type": "text"
      },
      "source": [
        "###### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGu90nsQDaud",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "0c30a7a2-2861-4591-9f96-8771d2ec2841"
      },
      "source": [
        "train_history = model.fit(x=input_train, y=train[output_categories], \n",
        "                          validation_split=0.2, \n",
        "                          epochs=EPOCHS, verbose=1)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "152/152 [==============================] - 696s 5s/step - loss: 0.4243 - val_loss: 0.3935\n",
            "Epoch 2/3\n",
            "152/152 [==============================] - 688s 5s/step - loss: 0.3871 - val_loss: 0.3818\n",
            "Epoch 3/3\n",
            "152/152 [==============================] - 688s 5s/step - loss: 0.3734 - val_loss: 0.3773\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}